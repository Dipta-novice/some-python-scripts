{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "8cb763f3-dda0-4d69-9b1f-888e4f814880",
    "_uuid": "da7e03adc6d73f4a8314421b123e79e3a9747616"
   },
   "source": [
    "Importing Dataset and splitting features and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "e0c29ef6-3721-42af-a215-115f4e94ad4b",
    "_uuid": "4746ad2ad2e31d6d669f1eb13a0f842b386ab9e6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(r'C:\\Users\\USER\\Desktop\\Python\\Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "730a5fac-97c2-4f20-8e1f-8fdf7bc37e7a",
    "_uuid": "b618af3f0d62e3e0178a3b72bd3abd8988b4c134"
   },
   "source": [
    "Encoding categorical features which are __sex__ & __Geography__. We will also do one hot encoding for __Geography__ to avoid dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "58ee1d05-08fa-422c-a6f2-abbbf0da3c99",
    "_uuid": "60f818bcb98ca395e330e114282f977ad15f94ab",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "\n",
    "onehotencoder = OneHotEncoder(categorical_features=[1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "18c7d5b3-8e63-4baf-a321-8a55f23aad1f",
    "_uuid": "f57a6975fb45486ea7572bd5245801ef82435386"
   },
   "source": [
    "Splitting into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "1055560d-de4f-4b0d-8d43-2e31b4e9d292",
    "_uuid": "d115d2110cfed505076e4eb772b0ef45ea48a541",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "21f05e11-6057-4918-bea5-1374c07de1f2",
    "_uuid": "52b8d3d3fc14887cc23876c1e8ac20eeb0ca44ac",
    "collapsed": true
   },
   "source": [
    "Applying features scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "5ba8005f-5595-4e03-a060-d9b12109f0f8",
    "_uuid": "22fcf3b93053aa45e675f8dddc672db9c979ccf7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07a24a1a-1606-45a5-a372-e39cda29d883",
    "_uuid": "6003f2376c324dd052c16d730c2dc5ba7f54192c"
   },
   "source": [
    "Defining architecture for our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow==2.3 (from versions: 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.1, 2.16.0rc0, 2.16.1, 2.16.2, 2.17.0rc0, 2.17.0rc1, 2.17.0, 2.17.1, 2.18.0rc0, 2.18.0rc1, 2.18.0rc2, 2.18.0)\n",
      "ERROR: No matching distribution found for tensorflow==2.3\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "46b2dce0-37ab-40e8-9c38-882f9410a76e",
    "_uuid": "874b3337948f020eb79c3989c27e3c0af27b4fcf"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.keras.wrappers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwrappers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscikit_learn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KerasClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras.wrappers'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "def deep_model():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu', input_dim=12))\n",
    "    classifier.add(Dense(units=12, kernel_initializer='uniform', activation='relu'))\n",
    "    classifier.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7c9c4d90-ec40-449b-a107-04766e9c3ecb",
    "_uuid": "2e2da6bde9e65938aca767850f142cdb6900c9d4"
   },
   "source": [
    "Running our ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "4f70d33e-d500-4bda-9438-cefa661b0a25",
    "_uuid": "d2aeb83a2f98a72e4097f20993a5795ff40867a2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# classifier = load_model('Churn_Modelling.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "8383a13f-a226-4de0-ab17-444bf3b03fe3",
    "_uuid": "c6b010b51cfe2c9b8ccf29e21bd085e88338c32a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8000/8000 [==============================] - 4s 461us/step - loss: 0.4582 - acc: 0.7960\n",
      "Epoch 2/128\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.4243 - acc: 0.8121\n",
      "Epoch 3/128\n",
      "8000/8000 [==============================] - 4s 441us/step - loss: 0.4192 - acc: 0.8285\n",
      "Epoch 4/128\n",
      "8000/8000 [==============================] - 4s 439us/step - loss: 0.4161 - acc: 0.8330\n",
      "Epoch 5/128\n",
      "8000/8000 [==============================] - 4s 441us/step - loss: 0.4132 - acc: 0.8322\n",
      "Epoch 6/128\n",
      "8000/8000 [==============================] - 3s 436us/step - loss: 0.4111 - acc: 0.8322\n",
      "Epoch 7/128\n",
      "8000/8000 [==============================] - 4s 450us/step - loss: 0.4092 - acc: 0.8345\n",
      "Epoch 8/128\n",
      "8000/8000 [==============================] - 4s 441us/step - loss: 0.4088 - acc: 0.8343\n",
      "Epoch 9/128\n",
      "8000/8000 [==============================] - 3s 436us/step - loss: 0.4090 - acc: 0.8327\n",
      "Epoch 10/128\n",
      "8000/8000 [==============================] - 4s 440us/step - loss: 0.4077 - acc: 0.8344\n",
      "Epoch 11/128\n",
      "8000/8000 [==============================] - 3s 436us/step - loss: 0.4071 - acc: 0.8361\n",
      "Epoch 12/128\n",
      "8000/8000 [==============================] - 3s 430us/step - loss: 0.4061 - acc: 0.8353\n",
      "Epoch 13/128\n",
      "8000/8000 [==============================] - 3s 434us/step - loss: 0.4058 - acc: 0.8339\n",
      "Epoch 14/128\n",
      "8000/8000 [==============================] - 3s 426us/step - loss: 0.4047 - acc: 0.8360\n",
      "Epoch 15/128\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 0.4035 - acc: 0.8357\n",
      "Epoch 16/128\n",
      "8000/8000 [==============================] - 3s 427us/step - loss: 0.4031 - acc: 0.8349\n",
      "Epoch 17/128\n",
      "8000/8000 [==============================] - 3s 428us/step - loss: 0.4036 - acc: 0.8345\n",
      "Epoch 18/128\n",
      "8000/8000 [==============================] - 3s 432us/step - loss: 0.4012 - acc: 0.8363\n",
      "Epoch 19/128\n",
      "8000/8000 [==============================] - 3s 434us/step - loss: 0.4025 - acc: 0.8351\n",
      "Epoch 20/128\n",
      "8000/8000 [==============================] - 4s 440us/step - loss: 0.4025 - acc: 0.8355\n",
      "Epoch 21/128\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.4018 - acc: 0.8351\n",
      "Epoch 22/128\n",
      "8000/8000 [==============================] - 3s 427us/step - loss: 0.4019 - acc: 0.8377\n",
      "Epoch 23/128\n",
      "8000/8000 [==============================] - 3s 414us/step - loss: 0.4029 - acc: 0.8381\n",
      "Epoch 24/128\n",
      "8000/8000 [==============================] - 3s 434us/step - loss: 0.4032 - acc: 0.8376\n",
      "Epoch 25/128\n",
      "8000/8000 [==============================] - 4s 440us/step - loss: 0.4034 - acc: 0.8377\n",
      "Epoch 26/128\n",
      "8000/8000 [==============================] - 3s 433us/step - loss: 0.4024 - acc: 0.8356\n",
      "Epoch 27/128\n",
      "8000/8000 [==============================] - 4s 442us/step - loss: 0.4033 - acc: 0.8393\n",
      "Epoch 28/128\n",
      "8000/8000 [==============================] - 4s 438us/step - loss: 0.4037 - acc: 0.8381\n",
      "Epoch 29/128\n",
      "8000/8000 [==============================] - 4s 439us/step - loss: 0.4039 - acc: 0.8387\n",
      "Epoch 30/128\n",
      "8000/8000 [==============================] - 3s 437us/step - loss: 0.4033 - acc: 0.8370\n",
      "Epoch 31/128\n",
      "8000/8000 [==============================] - 3s 395us/step - loss: 0.4028 - acc: 0.8381\n",
      "Epoch 32/128\n",
      "8000/8000 [==============================] - 3s 413us/step - loss: 0.4029 - acc: 0.8364\n",
      "Epoch 33/128\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.4030 - acc: 0.8383\n",
      "Epoch 34/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.4038 - acc: 0.8383\n",
      "Epoch 35/128\n",
      "8000/8000 [==============================] - 3s 409us/step - loss: 0.4044 - acc: 0.8366\n",
      "Epoch 36/128\n",
      "8000/8000 [==============================] - 3s 416us/step - loss: 0.4035 - acc: 0.8387\n",
      "Epoch 37/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.4044 - acc: 0.8384\n",
      "Epoch 38/128\n",
      "8000/8000 [==============================] - 3s 406us/step - loss: 0.4038 - acc: 0.8387\n",
      "Epoch 39/128\n",
      "8000/8000 [==============================] - 3s 414us/step - loss: 0.4034 - acc: 0.8380\n",
      "Epoch 40/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.4027 - acc: 0.8379\n",
      "Epoch 41/128\n",
      "8000/8000 [==============================] - 3s 414us/step - loss: 0.4045 - acc: 0.8370\n",
      "Epoch 42/128\n",
      "8000/8000 [==============================] - 3s 416us/step - loss: 0.4025 - acc: 0.8379\n",
      "Epoch 43/128\n",
      "8000/8000 [==============================] - 3s 407us/step - loss: 0.4013 - acc: 0.8370\n",
      "Epoch 44/128\n",
      "8000/8000 [==============================] - 3s 415us/step - loss: 0.3990 - acc: 0.8385\n",
      "Epoch 45/128\n",
      "8000/8000 [==============================] - 3s 412us/step - loss: 0.3964 - acc: 0.8394\n",
      "Epoch 46/128\n",
      "8000/8000 [==============================] - 3s 414us/step - loss: 0.3930 - acc: 0.8390\n",
      "Epoch 47/128\n",
      "8000/8000 [==============================] - 3s 410us/step - loss: 0.3906 - acc: 0.8412\n",
      "Epoch 48/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3836 - acc: 0.8445\n",
      "Epoch 49/128\n",
      "8000/8000 [==============================] - 3s 426us/step - loss: 0.3817 - acc: 0.8461\n",
      "Epoch 50/128\n",
      "8000/8000 [==============================] - 3s 421us/step - loss: 0.3783 - acc: 0.8470\n",
      "Epoch 51/128\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 0.3749 - acc: 0.8482\n",
      "Epoch 52/128\n",
      "8000/8000 [==============================] - 3s 418us/step - loss: 0.3719 - acc: 0.8486\n",
      "Epoch 53/128\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.3686 - acc: 0.8509\n",
      "Epoch 54/128\n",
      "8000/8000 [==============================] - 3s 418us/step - loss: 0.3653 - acc: 0.8538\n",
      "Epoch 55/128\n",
      "8000/8000 [==============================] - 3s 415us/step - loss: 0.3651 - acc: 0.8546\n",
      "Epoch 56/128\n",
      "8000/8000 [==============================] - 3s 413us/step - loss: 0.3641 - acc: 0.8563\n",
      "Epoch 57/128\n",
      "8000/8000 [==============================] - 3s 416us/step - loss: 0.3629 - acc: 0.8586\n",
      "Epoch 58/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3610 - acc: 0.8579\n",
      "Epoch 59/128\n",
      "8000/8000 [==============================] - 3s 418us/step - loss: 0.3619 - acc: 0.8581\n",
      "Epoch 60/128\n",
      "8000/8000 [==============================] - 3s 421us/step - loss: 0.3601 - acc: 0.8572\n",
      "Epoch 61/128\n",
      "8000/8000 [==============================] - 3s 415us/step - loss: 0.3592 - acc: 0.8591\n",
      "Epoch 62/128\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 0.3603 - acc: 0.8592\n",
      "Epoch 63/128\n",
      "8000/8000 [==============================] - 3s 417us/step - loss: 0.3594 - acc: 0.8633\n",
      "Epoch 64/128\n",
      "8000/8000 [==============================] - 3s 423us/step - loss: 0.3587 - acc: 0.8600\n",
      "Epoch 65/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3568 - acc: 0.8599\n",
      "Epoch 66/128\n",
      "8000/8000 [==============================] - 3s 415us/step - loss: 0.3560 - acc: 0.8605\n",
      "Epoch 67/128\n",
      "8000/8000 [==============================] - 3s 422us/step - loss: 0.3543 - acc: 0.8602\n",
      "Epoch 68/128\n",
      "8000/8000 [==============================] - 3s 426us/step - loss: 0.3574 - acc: 0.8608\n",
      "Epoch 69/128\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 0.3562 - acc: 0.8620\n",
      "Epoch 70/128\n",
      "8000/8000 [==============================] - 4s 457us/step - loss: 0.3561 - acc: 0.8622\n",
      "Epoch 71/128\n",
      "8000/8000 [==============================] - 4s 458us/step - loss: 0.3542 - acc: 0.8615\n",
      "Epoch 72/128\n",
      "8000/8000 [==============================] - 4s 481us/step - loss: 0.3557 - acc: 0.8605\n",
      "Epoch 73/128\n",
      "8000/8000 [==============================] - 4s 456us/step - loss: 0.3555 - acc: 0.8615\n",
      "Epoch 74/128\n",
      "8000/8000 [==============================] - 4s 458us/step - loss: 0.3563 - acc: 0.8636\n",
      "Epoch 75/128\n",
      "8000/8000 [==============================] - 4s 466us/step - loss: 0.3532 - acc: 0.8628\n",
      "Epoch 76/128\n",
      "8000/8000 [==============================] - 4s 469us/step - loss: 0.3556 - acc: 0.8631\n",
      "Epoch 77/128\n",
      "8000/8000 [==============================] - 4s 461us/step - loss: 0.3555 - acc: 0.8626\n",
      "Epoch 78/128\n",
      "8000/8000 [==============================] - 4s 449us/step - loss: 0.3574 - acc: 0.8628\n",
      "Epoch 79/128\n",
      "8000/8000 [==============================] - 4s 445us/step - loss: 0.3560 - acc: 0.8625\n",
      "Epoch 80/128\n",
      "8000/8000 [==============================] - 4s 454us/step - loss: 0.3567 - acc: 0.8621\n",
      "Epoch 81/128\n",
      "8000/8000 [==============================] - 4s 455us/step - loss: 0.3539 - acc: 0.8614\n",
      "Epoch 82/128\n",
      "8000/8000 [==============================] - 4s 452us/step - loss: 0.3560 - acc: 0.8654\n",
      "Epoch 83/128\n",
      "8000/8000 [==============================] - 4s 461us/step - loss: 0.3552 - acc: 0.8628\n",
      "Epoch 84/128\n",
      "8000/8000 [==============================] - 4s 455us/step - loss: 0.3577 - acc: 0.8601\n",
      "Epoch 85/128\n",
      "8000/8000 [==============================] - 3s 413us/step - loss: 0.3585 - acc: 0.8619\n",
      "Epoch 86/128\n",
      "8000/8000 [==============================] - 3s 409us/step - loss: 0.3597 - acc: 0.8636\n",
      "Epoch 87/128\n",
      "8000/8000 [==============================] - 3s 416us/step - loss: 0.3603 - acc: 0.8625\n",
      "Epoch 88/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3604 - acc: 0.8620\n",
      "Epoch 89/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3583 - acc: 0.8622\n",
      "Epoch 90/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3593 - acc: 0.8645\n",
      "Epoch 91/128\n",
      "8000/8000 [==============================] - 3s 420us/step - loss: 0.3616 - acc: 0.8634\n",
      "Epoch 92/128\n",
      "8000/8000 [==============================] - 3s 427us/step - loss: 0.3600 - acc: 0.8635\n",
      "Epoch 93/128\n",
      "8000/8000 [==============================] - 3s 411us/step - loss: 0.3595 - acc: 0.8645\n",
      "Epoch 94/128\n",
      "7080/8000 [=========================>....] - ETA: 0s - loss: 0.3650 - acc: 0.8647"
     ]
    }
   ],
   "source": [
    "# Uncomment to train new model otherwise it will used trained model\n",
    "classifier = deep_model()\n",
    "classifier.fit(X_train, y_train, batch_size=4, epochs=128)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "accuracy = (cm[0][0]+cm[1][1])/(cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "print(\"Accuracy: \"+ str(accuracy*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "f8c1c7e7-c504-49b5-8fd7-f7d7e97adf76",
    "_uuid": "69e59882c6b0ee872015101e4a77d139335bae9d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.save('Churn_Modelling.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "67ba0847-dead-4486-8a0a-04a7c8e7cfe5",
    "_uuid": "14910693628449461e671e4a3f1761732de282b1",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
